---
title: 微积分
---
## 0.1. 梯度
```
latex 表示  $\nabla$
```
假设x为n维向量，微分多元函数时使用以下规则：
对于所有$A\in\mathbb{R}^{m\times n}$,都有 $\nabla_xAx=A^T$

解释：
在微分多元函数中，对于一个固定的矩阵 \( A \in \mathbb{R}^{m \times n} \) 和一个 \( n \) 维向量 \( x \)，我们可以通过以下推导来理解为什么 \(\nabla_x(Ax) = A^T\)。

首先，设 \( y = Ax \)，那么 \( y \) 是一个 \( m \) 维向量，具体形式为：
$$
y_i = \sum_{j=1}^{n} a_{ij} x_j
$$

其中 \( a_{ij} \) 是矩阵 \( A \) 中第 \( i \) 行第 \( j \) 列的元素。

接下来，我们要计算 \( y \) 关于 \( x \) 的梯度 \( \nabla_x y \)。根据定义，梯度是一种偏导数的集合。

对于每个 \( i \)（即 \( y_i \) 的分量），对 \( x_j \) 取偏导数时，有：

$$
\frac{\partial y_i}{\partial x_j} = a_{ij}
$$

这样，我们可以将 \( \nabla_x y \) 表示为一个 \( m \times n \) 的雅可比矩阵：
$$

\nabla_x y = \begin{bmatrix}
\frac{\partial y_1}{\partial x_1} & \frac{\partial y_1}{\partial x_2} & \cdots & \frac{\partial y_1}{\partial x_n} \\
\frac{\partial y_2}{\partial x_1} & \frac{\partial y_2}{\partial x_2} & \cdots & \frac{\partial y_2}{\partial x_n} \\
\vdots & \vdots & \ddots & \vdots \\
\frac{\partial y_m}{\partial x_1} & \frac{\partial y_m}{\partial x_2} & \cdots & \frac{\partial y_m}{\partial x_n}
\end{bmatrix} = \begin{bmatrix}
a_{11} & a_{12} & \cdots & a_{1n} \\
a_{21} & a_{22} & \cdots & a_{2n} \\
\vdots & \vdots & \ddots & \vdots \\
a_{m1} & a_{m2} & \cdots & a_{mn}
\end{bmatrix} = A

$$
但是这里需要注意的是，梯度的定义是列向量，所以为了得到最终的结果，我们需要得出 \( $\nabla_x(Ax)$ \) 矩阵的转置：

$$
\nabla_x (Ax) = A^T
$$

由此可得，当对 \( Ax \) 进行微分时，得到的结果是：

$$
\nabla_x (Ax) = A^T
$$

这个结论在多元微积分中是非常重要的，常用于优化和机器学习等领域。

$$\nabla_{x}x^Tx=2x$$